==================================================
スライド1: タイトル
==================================================

コマ1完了報告
環境構築とデータ確認

外国人労働者向け曖昧性判定システム
BERT二値分類モデル構築プロジェクト

2025年12月12日

==================================================
スライド2: 実施内容
==================================================

実施した4つのタスク

1. 環境構築
   ✓ 開発環境の整備
   ✓ 必要ライブラリのインストール
   ✓ GPU/CPU環境の確認

2. データ読み込み
   ✓ 全データファイルの正常性確認
   ✓ データ構造の確認

3. 探索的データ分析（EDA）
   ✓ ラベル分布分析
   ✓ 文字数・トークン数分析
   ✓ 頻出語分析

4. 可視化
   ✓ 4種類のグラフ生成

==================================================
スライド3: データセット概要
==================================================

データセット構成

┌──────────────────────────────────┐
│ 総データ数: 2,000件              │
├──────────────────────────────────┤
│ Train:  1,600件（80%）           │
│ Val:      200件（10%）           │
│ Test:     200件（10%）           │
└──────────────────────────────────┘

ラベル分布（すべて50:50）
┌──────────────────┬──────────────────┐
│ Label 0（明確）   │ Label 1（曖昧）   │
│    1,000件       │    1,000件       │
└──────────────────┴──────────────────┘

✅ 完璧な均等分布

==================================================
スライド4: 分析結果（数値）
==================================================

文字数・トークン数統計

┌──────────────┬────────┬────────┬────────┐
│              │ 最小   │ 最大   │ 平均   │
├──────────────┼────────┼────────┼────────┤
│ 文字数       │ 10文字 │ 49文字 │ 24.2文字│
│ トークン数   │ 9トークン│ 35トークン│ 18.0トークン│
└──────────────┴────────┴────────┴────────┘

重要な決定事項

▶ 推奨max_length: 29トークン
  （95%のデータをカバー）

==================================================
スライド5: 頻出語分析の発見
==================================================

明確な指示 vs 曖昧な指示

明確な指示（Label 0）の特徴
━━━━━━━━━━━━━━━━━━━━━━━━━
TOP 5 頻出語:
1. まで     (431回) ← 期限を示す
2. メール   (185回) ← 具体的手段
3. 今日     (167回) ← 明確な期限
4. 送信     (165回) ← 具体的動作
5. Excel    (142回) ← 具体的ツール

→ 期限・手段・動作が明確


曖昧な指示（Label 1）の特徴
━━━━━━━━━━━━━━━━━━━━━━━━━
TOP 5 頻出語:
1. よろしく   (154回) ← 抽象的依頼
2. 適当に     (93回)  ← 感覚的表現
3. あれ       (85回)  ← 指示代名詞
4. いつもの   (50回)  ← 暗黙知依存
5. 早めに     (46回)  ← 曖昧な期限

→ 抽象的・暗黙知・感覚的

==================================================
スライド6: 可視化結果
==================================================

生成したグラフ（4種類）

1. ラベル分布グラフ
   [label_distribution.png]
   → 50:50の完璧な均等分布を確認

2. 文字数分布グラフ
   [text_length_distribution.png]
   → 平均24.2文字、バランスの良い分布

3. トークン数分布グラフ
   [token_length_distribution.png]
   → max_length=29を決定

4. 頻出語分析グラフ
   [frequent_words.png]
   → Label 0とLabel 1の明確な違い

==================================================
スライド7: 重要な知見
==================================================

3つの重要な発見

1. データセットの品質が高い
   ✓ ラベルバランスが完璧（50:50）
   ✓ Train/Val/Testの分布が一貫
   ✓ 実際のビジネス指示文を反映

2. 明確/曖昧の違いは語彙に現れる
   ✓ 明確: 「まで」「今日」「送信」
   ✓ 曖昧: 「よろしく」「適当に」「あれ」
   → BERTで判定可能と期待

3. 学習に適したデータ
   ✓ トークン数が適切な範囲（平均18）
   ✓ max_length=29で95%をカバー
   → 効率的な学習が可能

==================================================
スライド8: 次のステップへの準備
==================================================

コマ2〜3への準備完了

学習パラメータ決定
┌─────────────────────────┬──────────┐
│ max_length              │ 29       │
│ batch_size              │ 16       │
│ モデル                  │ cl-tohoku/bert-base-japanese-v3 │
│ 目標精度（初回学習）      │ 70%以上  │
└─────────────────────────┴──────────┘

成果物
✅ EDAスクリプト
✅ 分析レポート
✅ 可視化グラフ（4種類）
✅ 頻出語詳細データ

==================================================
スライド9: まとめ
==================================================

コマ1: 環境構築とデータ確認 - 完了

✅ 完了した作業
  • 環境構築
  • データ確認
  • 探索的データ分析
  • 可視化

✅ 達成した成果
  • データ品質の確認
  • 学習パラメータの決定
  • 明確/曖昧の特徴把握

⏱️ 所要時間: 75分 / 90分（目標達成）

⏭️ 次: コマ2（BERT学習スクリプト作成）

==================================================
