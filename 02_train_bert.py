"""
BERTäºŒå€¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å¤–å›½äººåŠ´åƒè€…å‘ã‘ãƒ“ã‚¸ãƒã‚¹æŒ‡ç¤ºæ–‡ æ›–æ˜§æ€§åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import os
from datetime import datetime
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from transformers import (
    BertJapaneseTokenizer,
    BertForSequenceClassification,
    TrainingArguments,
    Trainer
)
try:
    from transformers import EarlyStoppingCallback
except ImportError:
    EarlyStoppingCallback = None
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ========================================
# è¨­å®š
# ========================================

CONFIG = {
    'model_name': 'cl-tohoku/bert-base-japanese-v3',
    'max_length': 29,  # ã‚³ãƒ1ã®EDAçµæœã‹ã‚‰æ±ºå®šï¼ˆ95%ã‚¿ã‚¤ãƒ«ï¼‰
    'batch_size': 16,
    'learning_rate': 2e-5,
    'num_epochs': 3,
    'weight_decay': 0.01,
    'warmup_steps': 100,
    'output_dir': './results',
    'logging_dir': './logs',
    'seed': 42
}

# ========================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ========================================

def load_jsonl(filepath):
    """
    JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    """
    data = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line))
    return data

def create_dataset():
    """
    HuggingFace Datasetå½¢å¼ã«å¤‰æ›
    """
    print("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    train_data = load_jsonl('train.jsonl')
    val_data = load_jsonl('val.jsonl')
    test_data = load_jsonl('test.jsonl')
    
    print(f"  - Train: {len(train_data)}ä»¶")
    print(f"  - Val: {len(val_data)}ä»¶")
    print(f"  - Test: {len(test_data)}ä»¶")
    
    # HuggingFace Datasetå½¢å¼ã«å¤‰æ›
    train_dataset = Dataset.from_dict({
        'text': [item['text'] for item in train_data],
        'label': [item['label'] for item in train_data]
    })
    
    val_dataset = Dataset.from_dict({
        'text': [item['text'] for item in val_data],
        'label': [item['label'] for item in val_data]
    })
    
    test_dataset = Dataset.from_dict({
        'text': [item['text'] for item in test_data],
        'label': [item['label'] for item in test_data]
    })
    
    dataset = DatasetDict({
        'train': train_dataset,
        'validation': val_dataset,
        'test': test_dataset
    })
    
    return dataset

# ========================================
# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
# ========================================

def tokenize_function(examples, tokenizer, max_length):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
    """
    return tokenizer(
        examples['text'],
        padding='max_length',
        truncation=True,
        max_length=max_length,
        return_tensors=None  # Datasetã§ä½¿ã†ã¨ãã¯None
    )

# ========================================
# è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
# ========================================

def compute_metrics(pred):
    """
    Accuracy, Precision, Recall, F1ã‚’è¨ˆç®—
    """
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average='binary'
    )
    acc = accuracy_score(labels, preds)
    
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# ========================================
# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
# ========================================

def plot_confusion_matrix(y_true, y_pred, save_path):
    """
    æ··åŒè¡Œåˆ—ã‚’ä½œæˆãƒ»ä¿å­˜
    """
    cm = confusion_matrix(y_true, y_pred)
    
    # figuresãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['æ˜ç¢º(0)', 'æ›–æ˜§(1)'],
                yticklabels=['æ˜ç¢º(0)', 'æ›–æ˜§(1)'])
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.title('Confusion Matrix')
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    print(f"  â†’ æ··åŒè¡Œåˆ—ã‚’ä¿å­˜: {save_path}")

# ========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ========================================

def main():
    print("="*60)
    print("BERTå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    print("å¤–å›½äººåŠ´åƒè€…å‘ã‘ãƒ“ã‚¸ãƒã‚¹æŒ‡ç¤ºæ–‡ æ›–æ˜§æ€§åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ")
    print("="*60)
    
    # ã‚·ãƒ¼ãƒ‰å›ºå®š
    torch.manual_seed(CONFIG['seed'])
    np.random.seed(CONFIG['seed'])
    
    # GPUç¢ºèª
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    if device.type == 'cuda':
        print(f"GPUå: {torch.cuda.get_device_name(0)}")
        print(f"GPUãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # è¨­å®šã®è¡¨ç¤º
    print("\n--- å­¦ç¿’è¨­å®š ---")
    for key, value in CONFIG.items():
        print(f"  {key}: {value}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    print("\n[1/6] ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ä¸­...")
    dataset = create_dataset()
    print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†")
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    print("\n[2/6] ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ä¸­...")
    tokenizer = BertJapaneseTokenizer.from_pretrained(CONFIG['model_name'])
    print(f"âœ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–å®Œäº†")
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
    print("\n[3/6] ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºä¸­...")
    tokenized_datasets = dataset.map(
        lambda x: tokenize_function(x, tokenizer, CONFIG['max_length']),
        batched=True,
        desc="Tokenizing"
    )
    print(f"âœ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå®Œäº†")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("\n[4/6] ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    model = BertForSequenceClassification.from_pretrained(
        CONFIG['model_name'],
        num_labels=2
    )
    model.to(device)
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¡¨ç¤º
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"âœ“ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
    print(f"  - ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
    print(f"  - å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
    
    # å­¦ç¿’è¨­å®š
    print("\n[5/6] å­¦ç¿’è¨­å®šä¸­...")
    training_args = TrainingArguments(
        output_dir=CONFIG['output_dir'],
        evaluation_strategy='epoch',
        save_strategy='epoch',
        learning_rate=CONFIG['learning_rate'],
        per_device_train_batch_size=CONFIG['batch_size'],
        per_device_eval_batch_size=CONFIG['batch_size'],
        num_train_epochs=CONFIG['num_epochs'],
        weight_decay=CONFIG['weight_decay'],
        warmup_steps=CONFIG['warmup_steps'],
        logging_dir=CONFIG['logging_dir'],
        logging_steps=50,
        load_best_model_at_end=True,
        metric_for_best_model='f1',
        seed=CONFIG['seed'],
        report_to='none'  # TensorBoardãªã©ã‚’ä½¿ã‚ãªã„å ´åˆ
    )
    print(f"âœ“ å­¦ç¿’è¨­å®šå®Œäº†")
    
    # TraineråˆæœŸåŒ–
    trainer_kwargs = {
        'model': model,
        'args': training_args,
        'train_dataset': tokenized_datasets['train'],
        'eval_dataset': tokenized_datasets['validation'],
        'compute_metrics': compute_metrics,
    }
    
    if EarlyStoppingCallback is not None:
        trainer_kwargs['callbacks'] = [EarlyStoppingCallback(early_stopping_patience=2)]
    
    trainer = Trainer(**trainer_kwargs)
    
    # å­¦ç¿’é–‹å§‹
    print("\n[6/6] å­¦ç¿’é–‹å§‹...")
    print("-"*60)
    start_time = datetime.now()
    train_result = trainer.train()
    end_time = datetime.now()
    
    # å­¦ç¿’çµæœã®è¡¨ç¤º
    print("\n" + "="*60)
    print("å­¦ç¿’å®Œäº†ï¼")
    print("="*60)
    elapsed_time = (end_time - start_time).total_seconds()
    print(f"å­¦ç¿’æ™‚é–“: {elapsed_time:.2f}ç§’ ({elapsed_time/60:.2f}åˆ†)")
    print(f"æœ€çµ‚Loss: {train_result.metrics['train_loss']:.4f}")
    
    # Validationãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    print("\n--- Validationçµæœ ---")
    val_results = trainer.evaluate()
    for key, value in val_results.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.4f}")
        else:
            print(f"  {key}: {value}")
    
    # Testãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    print("\n--- Testçµæœ ---")
    test_results = trainer.evaluate(tokenized_datasets['test'])
    for key, value in test_results.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.4f}")
        else:
            print(f"  {key}: {value}")
    
    # æ··åŒè¡Œåˆ—ã®ä½œæˆ
    print("\næ··åŒè¡Œåˆ—ã‚’ä½œæˆä¸­...")
    predictions = trainer.predict(tokenized_datasets['test'])
    y_pred = np.argmax(predictions.predictions, axis=1)
    y_true = predictions.label_ids
    
    plot_confusion_matrix(y_true, y_pred, 'figures/confusion_matrix.png')
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    print("\nãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")
    os.makedirs('./saved_model', exist_ok=True)
    model.save_pretrained('./saved_model')
    tokenizer.save_pretrained('./saved_model')
    print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: ./saved_model")
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    print("\nçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­...")
    results_summary = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'config': CONFIG,
        'training_time_seconds': elapsed_time,
        'train_loss': float(train_result.metrics['train_loss']),
        'val_results': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                       for k, v in val_results.items()},
        'test_results': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                        for k, v in test_results.items()}
    }
    
    with open('training_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)
    print(f"âœ“ çµæœä¿å­˜å®Œäº†: training_results.json")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ‰ ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸï¼")
    print("="*60)
    print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: ./saved_model")
    print(f"ğŸ“Š çµæœä¿å­˜å…ˆ: training_results.json")
    print(f"ğŸ“ˆ æ··åŒè¡Œåˆ—: figures/confusion_matrix.png")
    print("\n--- æœ€çµ‚ã‚¹ã‚³ã‚¢ ---")
    print(f"  Test Accuracy:  {test_results['eval_accuracy']:.2%}")
    print(f"  Test F1 Score:  {test_results['eval_f1']:.4f}")
    print(f"  Test Precision: {test_results['eval_precision']:.4f}")
    print(f"  Test Recall:    {test_results['eval_recall']:.4f}")
    print("="*60)

if __name__ == '__main__':
    main()


