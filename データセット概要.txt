================================================================================
ビジネス指示文 曖昧性判定データセット - 概要
================================================================================

作成日: 2025年11月28日
データ総数: 2,000件
形式: JSONL (JSON Lines)

================================================================================
ファイル構成
================================================================================

1. dataset.jsonl      - 全データ（2,000件）          338KB
2. train.jsonl        - 学習用（1,600件 / 80%）     271KB
3. val.jsonl          - 検証用（200件 / 10%）        34KB
4. test.jsonl         - テスト用（200件 / 10%）      34KB

5. generate_dataset.py  - データ生成スクリプト       15KB
6. check_dataset.py     - 品質チェックスクリプト     2.1KB
7. README.md            - 詳細ドキュメント           8.4KB

================================================================================
ラベル定義
================================================================================

Label 0: 明確な指示 (1,000件)
  - What（行動内容）と When（期限）が両方具体的
  - 外国人労働者が即座に行動に移せる
  - 例: 「今日の17時までに、A社向けの見積書をPDFで作成してください。」

Label 1: 曖昧な指示 (1,000件)
  - What または When が欠如している
  - 追加質問なしでは行動に移せない
  - 例: 「例の件、早めに対応しといて。」

================================================================================
データ統計
================================================================================

✓ ラベルバランス: 完全に 50:50
✓ 文字数範囲: 10〜49文字
✓ 平均文字数: 24.2文字
✓ バリエーション: 10業種 × 多様なシチュエーション × 3種類の口調

================================================================================
使用方法（Python）
================================================================================

# データ読み込み
import json
with open('train.jsonl', 'r', encoding='utf-8') as f:
    data = [json.loads(line) for line in f]

# HuggingFace Datasets
from datasets import load_dataset
dataset = load_dataset('json', data_files={
    'train': 'train.jsonl',
    'validation': 'val.jsonl',
    'test': 'test.jsonl'
})

================================================================================
BERT学習での使用例
================================================================================

推奨モデル: cl-tohoku/bert-base-japanese-v3
タスク: 二値分類（明確 vs 曖昧）
入力: ビジネス指示文テキスト
出力: Label 0（明確）または Label 1（曖昧）

学習パラメータ目安:
  - Batch size: 16
  - Learning rate: 2e-5
  - Epochs: 3-5
  - Max length: 128

================================================================================
品質チェック
================================================================================

実行コマンド:
  python check_dataset.py

確認項目:
  ☑ ラベル分布（50:50）
  ☑ データ数（train 1,600, val 200, test 200）
  ☑ 文字数統計
  ☑ サンプルデータ表示

================================================================================
研究目的
================================================================================

外国人労働者が日本の職場で直面する「曖昧な指示」によるミスコミュニケーション
を解決するため、BERTモデルで自動判定システムを構築する。

期待される効果:
  1. 曖昧な指示を自動検出
  2. 具体的な指示への書き換え支援
  3. 職場でのコミュニケーション円滑化
  4. 外国人労働者の作業効率向上

================================================================================


